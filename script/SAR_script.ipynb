{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/palak-khanna/SAR-images-colorizer/blob/EDA-AIML/script/SAR_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjK8azFDs42J",
        "outputId": "c64232a5-e483-49a2-ae7a-291e83c577dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set up necessary imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLAPZzvbKllX"
      },
      "outputs": [],
      "source": [
        "# U-Net Generator Class\n",
        "class UNetGenerator(nn.Module):\n",
        "  def __init__(self):\n",
        "        super(UNetGenerator, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.enc1 = self.conv_block(3, 64)  # Update input channels to 3\n",
        "        self.enc2 = self.conv_block(64, 128)\n",
        "        self.enc3 = self.conv_block(128, 256)\n",
        "        self.enc4 = self.conv_block(256, 512)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = self.conv_block(512, 1024)\n",
        "\n",
        "        # Decoder\n",
        "        self.dec4 = self.conv_block(1024, 512)\n",
        "        self.dec3 = self.conv_block(512, 256)\n",
        "        self.dec2 = self.conv_block(256, 128)\n",
        "        self.dec1 = self.conv_block(128, 64)\n",
        "\n",
        "        # Final output layer (outputs 3 channels)\n",
        "        self.final = nn.Conv2d(64, 3, kernel_size=1)  # Output 3 channels for RGB\n",
        "\n",
        "  def conv_block(self, in_channels, out_channels):\n",
        "      block = nn.Sequential(\n",
        "          nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "          nn.BatchNorm2d(out_channels),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "          nn.BatchNorm2d(out_channels),\n",
        "          nn.ReLU(inplace=True)\n",
        "      )\n",
        "      return block\n",
        "\n",
        "  def forward(self, x):\n",
        "      # Encoding path\n",
        "      enc1 = self.enc1(x)  # Size: [B, 64, 256, 256]\n",
        "      enc2 = self.enc2(F.max_pool2d(enc1, 2))  # Size: [B, 128, 128, 128]\n",
        "      enc3 = self.enc3(F.max_pool2d(enc2, 2))  # Size: [B, 256, 64, 64]\n",
        "      enc4 = self.enc4(F.max_pool2d(enc3, 2))  # Size: [B, 512, 32, 32]\n",
        "\n",
        "      # Bottleneck\n",
        "      bottleneck = self.bottleneck(F.max_pool2d(enc4, 2))\n",
        "\n",
        "      # Decoding path\n",
        "      dec4 = self.dec4(F.interpolate(bottleneck, scale_factor=2, mode='nearest'))\n",
        "      dec3 = self.dec3(F.interpolate(dec4, scale_factor=2, mode='nearest'))\n",
        "      dec2 = self.dec2(F.interpolate(dec3, scale_factor=2, mode='nearest'))\n",
        "      dec1 = self.dec1(F.interpolate(dec2, scale_factor=2, mode='nearest'))\n",
        "\n",
        "      # Final output layer\n",
        "      output = self.final(dec1)  # Output should be [B, 3, 256, 256]\n",
        "\n",
        "      return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBFGn_DsKxu5"
      },
      "outputs": [],
      "source": [
        "# Define PatchGAN Discriminator\n",
        "class PatchGANDiscriminator(nn.Module):\n",
        "    def __init__(self, input_channels=6):  # Update input_channels to 6\n",
        "        super(PatchGANDiscriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 64, kernel_size=4, stride=2, padding=1),  # Now expecting 6 channels\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img_A, img_B):\n",
        "        # Concatenate along the channel dimension\n",
        "        input = torch.cat((img_A, img_B), 1)\n",
        "        return self.model(input)\n",
        "\n",
        "# ----------------------------\n",
        "# Loss Functions and Optimizers\n",
        "# ----------------------------\n",
        "criterion_GAN = nn.MSELoss()\n",
        "criterion_pixelwise = nn.L1Loss()  # L1 loss (MAE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOzMpUDELH0l"
      },
      "outputs": [],
      "source": [
        "# Dataset Class\n",
        "class SARToColorDataset(Dataset):\n",
        "    def __init__(self, data_dir, category, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.category = category\n",
        "        self.transform = transform\n",
        "        self.image_pairs = self._load_image_pairs()\n",
        "\n",
        "    def _load_image_pairs(self):\n",
        "        image_pairs = []\n",
        "        s1_dir = os.path.join(self.data_dir, self.category, \"s1\")\n",
        "        s2_dir = os.path.join(self.data_dir, self.category, \"s2\")\n",
        "\n",
        "        s1_images = sorted(os.listdir(s1_dir))\n",
        "        s2_images = sorted(os.listdir(s2_dir))\n",
        "\n",
        "        for s1_img, s2_img in zip(s1_images, s2_images):\n",
        "            image_pairs.append((os.path.join(s1_dir, s1_img), os.path.join(s2_dir, s2_img)))\n",
        "        return image_pairs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        s1_img_path, s2_img_path = self.image_pairs[idx]\n",
        "\n",
        "        # Load Sentinel-1 as grayscale and Sentinel-2 as RGB\n",
        "        s1_img = Image.open(s1_img_path).convert(\"L\")  # Load as single channel\n",
        "        s2_img = Image.open(s2_img_path).convert(\"RGB\")  # Load as RGB\n",
        "\n",
        "        # Resize both images to 256x256\n",
        "        resize = transforms.Resize((256, 256))\n",
        "        s1_img = resize(s1_img)\n",
        "        s2_img = resize(s2_img)\n",
        "\n",
        "        # Convert to tensors\n",
        "        s1_img = transforms.ToTensor()(s1_img)  # This will be [1, H, W]\n",
        "        s2_img = transforms.ToTensor()(s2_img)   # This will be [3, H, W]\n",
        "\n",
        "        # Replicate the single channel to create a 3-channel grayscale image\n",
        "        s1_img = s1_img.repeat(3, 1, 1)  # From [1, H, W] -> [3, H, W]\n",
        "\n",
        "        # Ensure both images have the same size\n",
        "        assert s1_img.size() == s2_img.size(), f\"Image sizes do not match: {s1_img.size()} vs {s2_img.size()}\"\n",
        "\n",
        "        return s1_img, s2_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4fLklUeLIfe"
      },
      "outputs": [],
      "source": [
        "# ----------------------------\n",
        "# Training and Testing Functions\n",
        "# ----------------------------\n",
        "def train(generator, discriminator, dataloader, optimizer_G, optimizer_D, epochs=10):\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "\n",
        "    G_losses, D_losses = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i, (sar_img, color_img) in enumerate(dataloader):\n",
        "            sar_img = sar_img.to(device)  # Keep this if you have to explicitly specify\n",
        "            color_img = color_img.to(device)  # Keep this if you have to explicitly specify\n",
        "\n",
        "            # Train Generator\n",
        "            optimizer_G.zero_grad()\n",
        "            gen_color = generator(sar_img)\n",
        "            validity = discriminator(sar_img, gen_color)\n",
        "\n",
        "            g_loss = criterion_GAN(validity, torch.ones_like(validity).to(device)) + criterion_pixelwise(gen_color, color_img)\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            # Train Discriminator\n",
        "            optimizer_D.zero_grad()\n",
        "            real_loss = criterion_GAN(discriminator(sar_img, color_img), torch.ones_like(validity).to(device))\n",
        "            fake_loss = criterion_GAN(discriminator(sar_img, gen_color.detach()), torch.zeros_like(validity).to(device))\n",
        "            d_loss = (real_loss + fake_loss) / 2\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # Store losses\n",
        "            G_losses.append(g_loss.item())\n",
        "            D_losses.append(d_loss.item())\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs} | Generator Loss: {g_loss.item()} | Discriminator Loss: {d_loss.item()}\")\n",
        "\n",
        "    return G_losses, D_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_2xOc-ELaIr"
      },
      "outputs": [],
      "source": [
        "def test_and_visualize(generator, dataloader):\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (sar_img, color_img) in enumerate(dataloader):\n",
        "            sar_img = sar_img.to(device)\n",
        "            color_img = color_img.to(device)  # Move color_img to the same device as sar_img\n",
        "\n",
        "            gen_color = generator(sar_img)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            accuracy = calculate_accuracy(gen_color, color_img)\n",
        "\n",
        "            # Visualization\n",
        "            plt.subplot(1, 3, 1)\n",
        "            plt.title(\"SAR Image\")\n",
        "            plt.imshow(sar_img[0].cpu().numpy().transpose(1, 2, 0), cmap=\"gray\")\n",
        "\n",
        "            plt.subplot(1, 3, 2)\n",
        "            plt.title(\"Generated Color\")\n",
        "            plt.imshow(gen_color[0].cpu().numpy().transpose(1, 2, 0))\n",
        "\n",
        "            plt.subplot(1, 3, 3)\n",
        "            plt.title(\"Ground Truth\")\n",
        "            plt.imshow(color_img[0].cpu().numpy().transpose(1, 2, 0))\n",
        "\n",
        "            plt.suptitle(f'Accuracy: {accuracy:.2f}%')\n",
        "            plt.show()\n",
        "\n",
        "            break  # Only visualize one batch\n",
        "\n",
        "\n",
        "# Function to calculate accuracy\n",
        "def calculate_accuracy(pred, target):\n",
        "    pred = (pred > 0.5).float()  # Convert to binary\n",
        "    target = (target > 0.5).float()  # Convert to binary\n",
        "    correct = (pred == target).sum()\n",
        "    total = target.numel()\n",
        "    return (correct / total) * 100\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "kjX2eE3wMKK8",
        "outputId": "4c993073-12f5-4b7f-d7ff-bc7548d96901"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on category: agri\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Set the data directory (e.g., Google Drive path)\n",
        "    data_dir = \"/content/drive/MyDrive/SIH 2024/SIH 2024 data\"\n",
        "\n",
        "    categories = [\"urban\"]  # Order of categories to train on\n",
        "\n",
        "    # Initialize models\n",
        "    generator = UNetGenerator().to(device)\n",
        "    discriminator = PatchGANDiscriminator().to(device)\n",
        "\n",
        "    # Optimizers\n",
        "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "    for category in categories:\n",
        "        print(f\"Training on category: {category}\")\n",
        "        # Initialize dataset and dataloader for the current category\n",
        "        dataset = SARToColorDataset(data_dir, category, transform=None)\n",
        "        dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)\n",
        "\n",
        "        # Train the model\n",
        "        G_losses, D_losses = train(generator, discriminator, dataloader, optimizer_G, optimizer_D, epochs=5)\n",
        "\n",
        "        # Test and visualize results\n",
        "        test_and_visualize(generator, dataloader)\n",
        "\n",
        "        # Optionally, you can save the model after each category\n",
        "        torch.save(generator.state_dict(), f\"{category}_generator.pth\")\n",
        "        torch.save(discriminator.state_dict(), f\"{category}_discriminator.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}